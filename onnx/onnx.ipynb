{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "802de0d4-276a-4f51-87db-de54310cc559",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1: onnx.TensorProto.FLOAT\n",
      " 2: onnx.TensorProto.UINT8\n",
      " 3: onnx.TensorProto.INT8\n",
      " 4: onnx.TensorProto.UINT16\n",
      " 5: onnx.TensorProto.INT16\n",
      " 6: onnx.TensorProto.INT32\n",
      " 7: onnx.TensorProto.INT64\n",
      " 8: onnx.TensorProto.STRING\n",
      " 9: onnx.TensorProto.BOOL\n",
      "10: onnx.TensorProto.FLOAT16\n",
      "11: onnx.TensorProto.DOUBLE\n",
      "12: onnx.TensorProto.UINT32\n",
      "13: onnx.TensorProto.UINT64\n",
      "14: onnx.TensorProto.COMPLEX64\n",
      "15: onnx.TensorProto.COMPLEX128\n",
      "16: onnx.TensorProto.BFLOAT16\n",
      "17: onnx.TensorProto.FLOAT8E4M3FN\n",
      "18: onnx.TensorProto.FLOAT8E4M3FNUZ\n",
      "19: onnx.TensorProto.FLOAT8E5M2\n",
      "20: onnx.TensorProto.FLOAT8E5M2FNUZ\n",
      "21: onnx.TensorProto.UINT4\n",
      "22: onnx.TensorProto.INT4\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from onnx import TensorProto\n",
    "\n",
    "reg = re.compile('^[0-9A-Z_]+$')\n",
    "\n",
    "values = {}\n",
    "for att in sorted(dir(TensorProto)):\n",
    "    if att in {'DESCRIPTOR'}:\n",
    "        continue\n",
    "    if reg.match(att):\n",
    "        values[getattr(TensorProto, att)] = att\n",
    "for i, att in sorted(values.items()):\n",
    "    si = str(i)\n",
    "    if len(si) == 1:\n",
    "        si = \" \" + si\n",
    "    print(\"%s: onnx.TensorProto.%s\" % (si, att))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2b30df7-4d09-401b-b15c-cb3c996f3406",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16.0  opset= 21\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "print(onnx.__version__, \" opset=\", onnx.defs.onnx_opset_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fd17542-cfef-47fd-97f3-9928a6cead7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ir_version: 10\n",
      "opset_import {\n",
      "  version: 21\n",
      "}\n",
      "graph {\n",
      "  node {\n",
      "    input: \"X\"\n",
      "    input: \"A\"\n",
      "    output: \"XA\"\n",
      "    op_type: \"MatMul\"\n",
      "  }\n",
      "  node {\n",
      "    input: \"XA\"\n",
      "    input: \"B\"\n",
      "    output: \"Y\"\n",
      "    op_type: \"Add\"\n",
      "  }\n",
      "  name: \"lr\"\n",
      "  input {\n",
      "    name: \"X\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  input {\n",
      "    name: \"A\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  input {\n",
      "    name: \"B\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  output {\n",
      "    name: \"Y\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "from onnx import TensorProto\n",
    "from onnx.helper import (\n",
    "    make_model, make_node, make_graph,\n",
    "    make_tensor_value_info)\n",
    "from onnx.checker import check_model\n",
    "\n",
    "# inputs\n",
    "\n",
    "# 'X' is the name, TensorProto.FLOAT the type, [None, None] the shape\n",
    "X = make_tensor_value_info('X', TensorProto.FLOAT, [None, None])\n",
    "A = make_tensor_value_info('A', TensorProto.FLOAT, [None, None])\n",
    "B = make_tensor_value_info('B', TensorProto.FLOAT, [None, None])\n",
    "\n",
    "# outputs, the shape is left undefined\n",
    "\n",
    "Y = make_tensor_value_info('Y', TensorProto.FLOAT, [None])\n",
    "\n",
    "# nodes\n",
    "\n",
    "# It creates a node defined by the operator type MatMul,\n",
    "# 'X', 'A' are the inputs of the node, 'XA' the output.\n",
    "node1 = make_node('MatMul', ['X', 'A'], ['XA'])\n",
    "node2 = make_node('Add', ['XA', 'B'], ['Y'])\n",
    "\n",
    "# from nodes to graph\n",
    "# the graph is built from the list of nodes, the list of inputs,\n",
    "# the list of outputs and a name.\n",
    "\n",
    "graph = make_graph([node1, node2],  # nodes\n",
    "                    'lr',  # a name\n",
    "                    [X, A, B],  # inputs\n",
    "                    [Y])  # outputs\n",
    "\n",
    "# onnx graph\n",
    "# there is no metadata in this case.\n",
    "\n",
    "onnx_model = make_model(graph)\n",
    "\n",
    "# Let's check the model is consistent,\n",
    "# this function is described in section\n",
    "# Checker and Shape Inference.\n",
    "check_model(onnx_model)\n",
    "\n",
    "# the work is done, let's display it...\n",
    "print(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c63039a0-8f84-45d3-8c18-e773c24e6686",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** inputs **\n",
      "[name: \"X\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "      }\n",
      "      dim {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", name: \"A\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "      }\n",
      "      dim {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ", name: \"B\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "      }\n",
      "      dim {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "]\n",
      "** inputs **\n",
      "name='X' dtype=1 shape=(0, 0)\n",
      "name='A' dtype=1 shape=(0, 0)\n",
      "name='B' dtype=1 shape=(0, 0)\n",
      "** outputs **\n",
      "[name: \"Y\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "]\n",
      "** outputs **\n",
      "name='Y' dtype=1 shape=(0,)\n",
      "** nodes **\n",
      "[input: \"X\"\n",
      "input: \"A\"\n",
      "output: \"XA\"\n",
      "op_type: \"MatMul\"\n",
      ", input: \"XA\"\n",
      "input: \"B\"\n",
      "output: \"Y\"\n",
      "op_type: \"Add\"\n",
      "]\n",
      "** nodes **\n",
      "name='' type='MatMul' input=['X', 'A'] output=['XA']\n",
      "name='' type='Add' input=['XA', 'B'] output=['Y']\n"
     ]
    }
   ],
   "source": [
    "from onnx import TensorProto\n",
    "from onnx.helper import (\n",
    "    make_model, make_node, make_graph,\n",
    "    make_tensor_value_info)\n",
    "from onnx.checker import check_model\n",
    "\n",
    "def shape2tuple(shape):\n",
    "    return tuple(getattr(d, 'dim_value', 0) for d in shape.dim)\n",
    "\n",
    "X = make_tensor_value_info('X', TensorProto.FLOAT, [None, None])\n",
    "A = make_tensor_value_info('A', TensorProto.FLOAT, [None, None])\n",
    "B = make_tensor_value_info('B', TensorProto.FLOAT, [None, None])\n",
    "Y = make_tensor_value_info('Y', TensorProto.FLOAT, [None])\n",
    "node1 = make_node('MatMul', ['X', 'A'], ['XA'])\n",
    "node2 = make_node('Add', ['XA', 'B'], ['Y'])\n",
    "graph = make_graph([node1, node2], 'lr', [X, A, B], [Y])\n",
    "onnx_model = make_model(graph)\n",
    "check_model(onnx_model)\n",
    "\n",
    "# the list of inputs\n",
    "print('** inputs **')\n",
    "print(onnx_model.graph.input)\n",
    "\n",
    "# in a more nicely format\n",
    "print('** inputs **')\n",
    "for obj in onnx_model.graph.input:\n",
    "    print(\"name=%r dtype=%r shape=%r\" % (\n",
    "        obj.name, obj.type.tensor_type.elem_type,\n",
    "        shape2tuple(obj.type.tensor_type.shape)))\n",
    "\n",
    "# the list of outputs\n",
    "print('** outputs **')\n",
    "print(onnx_model.graph.output)\n",
    "\n",
    "# in a more nicely format\n",
    "print('** outputs **')\n",
    "for obj in onnx_model.graph.output:\n",
    "    print(\"name=%r dtype=%r shape=%r\" % (\n",
    "        obj.name, obj.type.tensor_type.elem_type,\n",
    "        shape2tuple(obj.type.tensor_type.shape)))\n",
    "\n",
    "# the list of nodes\n",
    "print('** nodes **')\n",
    "print(onnx_model.graph.node)\n",
    "\n",
    "# in a more nicely format\n",
    "print('** nodes **')\n",
    "for node in onnx_model.graph.node:\n",
    "    print(\"name=%r type=%r input=%r output=%r\" % (\n",
    "        node.name, node.op_type, node.input, node.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d885279-706d-409f-8e22-73f2cf39cf15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ir_version: 10\n",
      "opset_import {\n",
      "  version: 21\n",
      "}\n",
      "graph {\n",
      "  node {\n",
      "    input: \"X\"\n",
      "    input: \"A\"\n",
      "    output: \"XA\"\n",
      "    op_type: \"MatMul\"\n",
      "  }\n",
      "  node {\n",
      "    input: \"XA\"\n",
      "    input: \"B\"\n",
      "    output: \"Y\"\n",
      "    op_type: \"Add\"\n",
      "  }\n",
      "  name: \"lr\"\n",
      "  input {\n",
      "    name: \"X\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  input {\n",
      "    name: \"A\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  input {\n",
      "    name: \"B\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  output {\n",
      "    name: \"Y\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from onnx import TensorProto\n",
    "from onnx.helper import (\n",
    "    make_model, make_node, make_graph,\n",
    "    make_tensor_value_info)\n",
    "from onnx.checker import check_model\n",
    "\n",
    "def shape2tuple(shape):\n",
    "    return tuple(getattr(d, 'dim_value', 0) for d in shape.dim)\n",
    "\n",
    "X = make_tensor_value_info('X', TensorProto.FLOAT, [None, None])\n",
    "A = make_tensor_value_info('A', TensorProto.FLOAT, [None, None])\n",
    "B = make_tensor_value_info('B', TensorProto.FLOAT, [None, None])\n",
    "Y = make_tensor_value_info('Y', TensorProto.FLOAT, [None])\n",
    "node1 = make_node('MatMul', ['X', 'A'], ['XA'])\n",
    "node2 = make_node('Add', ['XA', 'B'], ['Y'])\n",
    "graph = make_graph([node1, node2], 'lr', [X, A, B], [Y])\n",
    "onnx_model = make_model(graph)\n",
    "check_model(onnx_model)\n",
    "\n",
    "# The serialization\n",
    "with open(\"linear_regression.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "# display\n",
    "print(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68e33589-b294-4e8b-a36f-0bcaf591f76a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ir_version: 10\n",
      "opset_import {\n",
      "  version: 21\n",
      "}\n",
      "graph {\n",
      "  node {\n",
      "    input: \"X\"\n",
      "    input: \"A\"\n",
      "    output: \"XA\"\n",
      "    op_type: \"MatMul\"\n",
      "  }\n",
      "  node {\n",
      "    input: \"XA\"\n",
      "    input: \"B\"\n",
      "    output: \"Y\"\n",
      "    op_type: \"Add\"\n",
      "  }\n",
      "  name: \"lr\"\n",
      "  input {\n",
      "    name: \"X\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  input {\n",
      "    name: \"A\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  input {\n",
      "    name: \"B\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  output {\n",
      "    name: \"Y\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from onnx import load\n",
    "\n",
    "with open(\"linear_regression.onnx\", \"rb\") as f:\n",
    "    onnx_model = load(f)\n",
    "\n",
    "# display\n",
    "print(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe9d0556-143f-4dd2-a4b6-0a2a0649ba9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'onnx.onnx_ml_pb2.TensorProto'>\n",
      "<class 'bytes'>\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from onnx.numpy_helper import from_array\n",
    "\n",
    "numpy_tensor = numpy.array([0, 1, 4, 5, 3], dtype=numpy.float32)\n",
    "print(type(numpy_tensor))\n",
    "\n",
    "onnx_tensor = from_array(numpy_tensor)\n",
    "print(type(onnx_tensor))\n",
    "\n",
    "serialized_tensor = onnx_tensor.SerializeToString()\n",
    "print(type(serialized_tensor))\n",
    "\n",
    "with open(\"saved_tensor.pb\", \"wb\") as f:\n",
    "    f.write(serialized_tensor)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78284b05-d96b-4ca3-bd0a-04f00e9eab0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'onnx.onnx_ml_pb2.TensorProto'>\n"
     ]
    }
   ],
   "source": [
    "from onnx import load_tensor_from_string\n",
    "\n",
    "with open(\"saved_tensor.pb\", \"rb\") as f:\n",
    "    serialized = f.read()\n",
    "proto = load_tensor_from_string(serialized)\n",
    "print(type(proto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a010178-b48a-41d6-9b32-4087baa863e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ir_version: 10\n",
      "opset_import {\n",
      "  version: 21\n",
      "}\n",
      "graph {\n",
      "  node {\n",
      "    input: \"X\"\n",
      "    input: \"A\"\n",
      "    output: \"AX\"\n",
      "    op_type: \"MatMul\"\n",
      "  }\n",
      "  node {\n",
      "    input: \"AX\"\n",
      "    input: \"C\"\n",
      "    output: \"Y\"\n",
      "    op_type: \"Add\"\n",
      "  }\n",
      "  name: \"lr\"\n",
      "  initializer {\n",
      "    dims: 2\n",
      "    data_type: 1\n",
      "    name: \"A\"\n",
      "    raw_data: \"\\000\\000\\000?\\232\\231\\031\\277\"\n",
      "  }\n",
      "  initializer {\n",
      "    dims: 1\n",
      "    data_type: 1\n",
      "    name: \"C\"\n",
      "    raw_data: \"\\315\\314\\314>\"\n",
      "  }\n",
      "  input {\n",
      "    name: \"X\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  output {\n",
      "    name: \"Y\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from onnx import numpy_helper, TensorProto\n",
    "from onnx.helper import (\n",
    "    make_model, make_node, make_graph,\n",
    "    make_tensor_value_info)\n",
    "from onnx.checker import check_model\n",
    "\n",
    "# initializers\n",
    "value = numpy.array([0.5, -0.6], dtype=numpy.float32)\n",
    "A = numpy_helper.from_array(value, name='A')\n",
    "\n",
    "value = numpy.array([0.4], dtype=numpy.float32)\n",
    "C = numpy_helper.from_array(value, name='C')\n",
    "\n",
    "# the part which does not change\n",
    "X = make_tensor_value_info('X', TensorProto.FLOAT, [None, None])\n",
    "Y = make_tensor_value_info('Y', TensorProto.FLOAT, [None])\n",
    "node1 = make_node('MatMul', ['X', 'A'], ['AX'])\n",
    "node2 = make_node('Add', ['AX', 'C'], ['Y'])\n",
    "graph = make_graph([node1, node2], 'lr', [X], [Y], [A, C])\n",
    "onnx_model = make_model(graph)\n",
    "check_model(onnx_model)\n",
    "\n",
    "print(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0dfc210-427d-406b-b396-8be213d7e585",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ir_version: 10\n",
      "opset_import {\n",
      "  version: 21\n",
      "}\n",
      "graph {\n",
      "  node {\n",
      "    input: \"A\"\n",
      "    output: \"tA\"\n",
      "    op_type: \"Transpose\"\n",
      "    attribute {\n",
      "      name: \"perm\"\n",
      "      type: INTS\n",
      "      ints: 1\n",
      "      ints: 0\n",
      "    }\n",
      "  }\n",
      "  node {\n",
      "    input: \"X\"\n",
      "    input: \"tA\"\n",
      "    output: \"XA\"\n",
      "    op_type: \"MatMul\"\n",
      "  }\n",
      "  node {\n",
      "    input: \"XA\"\n",
      "    input: \"B\"\n",
      "    output: \"Y\"\n",
      "    op_type: \"Add\"\n",
      "  }\n",
      "  name: \"lr\"\n",
      "  input {\n",
      "    name: \"X\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  input {\n",
      "    name: \"A\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  input {\n",
      "    name: \"B\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  output {\n",
      "    name: \"Y\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from onnx import TensorProto\n",
    "from onnx.helper import (\n",
    "    make_model, make_node, make_graph,\n",
    "    make_tensor_value_info)\n",
    "from onnx.checker import check_model\n",
    "\n",
    "# unchanged\n",
    "X = make_tensor_value_info('X', TensorProto.FLOAT, [None, None])\n",
    "A = make_tensor_value_info('A', TensorProto.FLOAT, [None, None])\n",
    "B = make_tensor_value_info('B', TensorProto.FLOAT, [None, None])\n",
    "Y = make_tensor_value_info('Y', TensorProto.FLOAT, [None])\n",
    "\n",
    "# added\n",
    "node_transpose = make_node('Transpose', ['A'], ['tA'], perm=[1, 0])\n",
    "\n",
    "# unchanged except A is replaced by tA\n",
    "node1 = make_node('MatMul', ['X', 'tA'], ['XA'])\n",
    "node2 = make_node('Add', ['XA', 'B'], ['Y'])\n",
    "\n",
    "# node_transpose is added to the list\n",
    "graph = make_graph([node_transpose, node1, node2],\n",
    "                   'lr', [X, A, B], [Y])\n",
    "onnx_model = make_model(graph)\n",
    "check_model(onnx_model)\n",
    "\n",
    "# the work is done, let's display it...\n",
    "print(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e412be90-7fe5-47ee-a23e-a1bac00b6e4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ir_version: 10\n",
      "opset domain='' version=21\n"
     ]
    }
   ],
   "source": [
    "from onnx import load\n",
    "\n",
    "with open(\"linear_regression.onnx\", \"rb\") as f:\n",
    "    onnx_model = load(f)\n",
    "\n",
    "print(\"ir_version:\", onnx_model.ir_version)\n",
    "for opset in onnx_model.opset_import:\n",
    "    print(\"opset domain=%r version=%r\" % (opset.domain, opset.version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8497bd4-ad68-41bf-95e5-7bb5eeb318b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result [array([1.], dtype=float32)]\n",
      "\n",
      "ir_version: 8\n",
      "opset_import {\n",
      "  domain: \"\"\n",
      "  version: 15\n",
      "}\n",
      "graph {\n",
      "  node {\n",
      "    input: \"X\"\n",
      "    output: \"rsum\"\n",
      "    op_type: \"ReduceSum\"\n",
      "  }\n",
      "  node {\n",
      "    input: \"rsum\"\n",
      "    input: \"zero\"\n",
      "    output: \"cond\"\n",
      "    op_type: \"Greater\"\n",
      "  }\n",
      "  node {\n",
      "    input: \"cond\"\n",
      "    output: \"Y\"\n",
      "    op_type: \"If\"\n",
      "    attribute {\n",
      "      name: \"else_branch\"\n",
      "      type: GRAPH\n",
      "      g {\n",
      "        node {\n",
      "          output: \"else_out\"\n",
      "          name: \"cst2\"\n",
      "          op_type: \"Constant\"\n",
      "          attribute {\n",
      "            name: \"value\"\n",
      "            type: TENSOR\n",
      "            t {\n",
      "              dims: 1\n",
      "              data_type: 1\n",
      "              raw_data: \"\\000\\000\\200\\277\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        name: \"else_body\"\n",
      "        output {\n",
      "          name: \"else_out\"\n",
      "          type {\n",
      "            tensor_type {\n",
      "              elem_type: 1\n",
      "              shape {\n",
      "                dim {\n",
      "                  dim_value: 5\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    attribute {\n",
      "      name: \"then_branch\"\n",
      "      type: GRAPH\n",
      "      g {\n",
      "        node {\n",
      "          output: \"then_out\"\n",
      "          name: \"cst1\"\n",
      "          op_type: \"Constant\"\n",
      "          attribute {\n",
      "            name: \"value\"\n",
      "            type: TENSOR\n",
      "            t {\n",
      "              dims: 1\n",
      "              data_type: 1\n",
      "              raw_data: \"\\000\\000\\200?\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        name: \"then_body\"\n",
      "        output {\n",
      "          name: \"then_out\"\n",
      "          type {\n",
      "            tensor_type {\n",
      "              elem_type: 1\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  name: \"if\"\n",
      "  initializer {\n",
      "    dims: 1\n",
      "    data_type: 1\n",
      "    name: \"zero\"\n",
      "    raw_data: \"\\000\\000\\000\\000\"\n",
      "  }\n",
      "  input {\n",
      "    name: \"X\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  output {\n",
      "    name: \"Y\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import onnx\n",
    "from onnx.helper import (\n",
    "    make_node, make_graph, make_model, make_tensor_value_info)\n",
    "from onnx.numpy_helper import from_array\n",
    "from onnx.checker import check_model\n",
    "from onnxruntime import InferenceSession\n",
    "\n",
    "# initializers\n",
    "value = numpy.array([0], dtype=numpy.float32)\n",
    "zero = from_array(value, name='zero')\n",
    "\n",
    "# Same as before, X is the input, Y is the output.\n",
    "X = make_tensor_value_info('X', onnx.TensorProto.FLOAT, [None, None])\n",
    "Y = make_tensor_value_info('Y', onnx.TensorProto.FLOAT, [None])\n",
    "\n",
    "# The node building the condition. The first one\n",
    "# sum over all axes.\n",
    "rsum = make_node('ReduceSum', ['X'], ['rsum'])\n",
    "# The second compares the result to 0.\n",
    "cond = make_node('Greater', ['rsum', 'zero'], ['cond'])\n",
    "\n",
    "# Builds the graph is the condition is True.\n",
    "# Input for then\n",
    "then_out = make_tensor_value_info(\n",
    "    'then_out', onnx.TensorProto.FLOAT, None)\n",
    "# The constant to return.\n",
    "then_cst = from_array(numpy.array([1]).astype(numpy.float32))\n",
    "\n",
    "# The only node.\n",
    "then_const_node = make_node(\n",
    "    'Constant', inputs=[],\n",
    "    outputs=['then_out'],\n",
    "    value=then_cst, name='cst1')\n",
    "\n",
    "# And the graph wrapping these elements.\n",
    "then_body = make_graph(\n",
    "    [then_const_node], 'then_body', [], [then_out])\n",
    "\n",
    "# Same process for the else branch.\n",
    "else_out = make_tensor_value_info(\n",
    "    'else_out', onnx.TensorProto.FLOAT, [5])\n",
    "else_cst = from_array(numpy.array([-1]).astype(numpy.float32))\n",
    "\n",
    "else_const_node = make_node(\n",
    "    'Constant', inputs=[],\n",
    "    outputs=['else_out'],\n",
    "    value=else_cst, name='cst2')\n",
    "\n",
    "else_body = make_graph(\n",
    "    [else_const_node], 'else_body',\n",
    "    [], [else_out])\n",
    "\n",
    "# Finally the node If taking both graphs as attributes.\n",
    "if_node = onnx.helper.make_node(\n",
    "    'If', ['cond'], ['Y'],\n",
    "    then_branch=then_body,\n",
    "    else_branch=else_body)\n",
    "\n",
    "# The final graph.\n",
    "graph = make_graph([rsum, cond, if_node], 'if', [X], [Y], [zero])\n",
    "onnx_model = make_model(graph)\n",
    "check_model(onnx_model)\n",
    "\n",
    "# Let's freeze the opset.\n",
    "del onnx_model.opset_import[:]\n",
    "opset = onnx_model.opset_import.add()\n",
    "opset.domain = ''\n",
    "opset.version = 15\n",
    "onnx_model.ir_version = 8\n",
    "\n",
    "# Save.\n",
    "with open(\"onnx_if_sign.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "# Let's see the output.\n",
    "sess = InferenceSession(onnx_model.SerializeToString(),\n",
    "                        providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "x = numpy.ones((3, 2), dtype=numpy.float32)\n",
    "res = sess.run(None, {'X': x})\n",
    "\n",
    "# It works.\n",
    "print(\"result\", res)\n",
    "print()\n",
    "\n",
    "# Some display.\n",
    "print(onnx_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3c61e9a-dce0-45a0-9555-d75b6b470a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model.\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X = X.astype(np.float32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "clr = RandomForestClassifier()\n",
    "clr.fit(X_train, y_train)\n",
    "\n",
    "# Convert into ONNX format.\n",
    "from skl2onnx import to_onnx\n",
    "\n",
    "onx = to_onnx(clr, X[:1])\n",
    "with open(\"rf_iris.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())\n",
    "\n",
    "# Compute the prediction with onnxruntime.\n",
    "import onnxruntime as rt\n",
    "\n",
    "sess = rt.InferenceSession(\"rf_iris.onnx\", providers=[\"CPUExecutionProvider\"])\n",
    "input_name = sess.get_inputs()[0].name\n",
    "label_name = sess.get_outputs()[0].name\n",
    "pred_onx = sess.run([label_name], {input_name: X_test.astype(np.float32)})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50ad2e4f-0398-4f8e-88a0-4147e8be086c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97ed0ea0-60d1-40f1-ac09-88148bdebac6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ee6742d-e88c-47c2-b08e-a0379f68e93f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e83bc87e-66c8-4cce-bd61-e727f2e6b20c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"rf_iris.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())\n",
    "\n",
    "# Compute the prediction with onnxruntime.\n",
    "import onnxruntime as rt\n",
    "\n",
    "sess = rt.InferenceSession(\"rf_iris.onnx\", providers=[\"CPUExecutionProvider\"])\n",
    "input_name = sess.get_inputs()[0].name\n",
    "label_name = sess.get_outputs()[0].name\n",
    "pred_onx = sess.run([label_name], {input_name: X_test.astype(np.float32)})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70e58450-7822-4700-92d7-616d35cdfbb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 2, 0, 1, 0, 1, 1, 1, 1, 2, 1, 2, 1, 2, 0, 1, 2, 0, 2, 0,\n",
       "       2, 0, 0, 0, 1, 0, 2, 1, 2, 2, 0, 0, 0, 1, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_onx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b69e21-1816-4b52-a0d1-b5facef51e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
