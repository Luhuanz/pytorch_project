![](https://files.mdnice.com/user/33808/dc8410e3-56c5-4815-ad71-5268c10b986c.png)

>YOLO社区自前两次发布一直情绪高涨！随着中国农历新年2023（兔年）的到来，美团对YOLOv6进行了许多新的网络架构和训练方案改进。此版本标识为YOLOv6 v3.0。
>
>对于性能，YOLOv6-N在COCO数据集上的AP为37.5%，通过NVIDIA Tesla T4 GPU测试的吞吐量为1187 FPS。YOLOv6-S以484 FPS的速度得到了超过45.0%的AP，超过了相同规模的其他主流检测器（YOLOv5-S、YOLOv8-S、YOLOX-S和PPYOLOE-S）。
>
>通过是，YOLOv6-M/L在相似的推理速度下也比其他检测器实现了更好的精度性能（分别为50.0%/52.8%）。此外，凭借扩展的Backbone和Neck设计，YOLOv6-L6实现了最先进的实时精度。

## 1、简介
YOLO系列一直是工业应用中最受欢迎的检测框架，因为其在速度和精度之间的出色平衡。YOLO系列的开创性作品是YOLOv1-3，它开辟了一条单级探测器的新道路，以及后来的重大改进。YOLOv4将检测框架重组为几个单独的部分（主干、颈部和头部），并验证了当时的免费赠品包和特价包，以设计适合在单个GPU上训练的框架。目前，YOLOv5、YOLOX、PPYOLOE、YOLOv7和最近的YOLOv8都是部署高效探测器的竞争对手。

在本版本中，我们对网络设计和培训策略进行了大力更新。我们在图1中显示了YOLOv6与其他对等体在类似规模下的比较。YOLOv6的新功能总结如下：

1. 我们用双向级联（BiC）模块更新检测器的颈部，以提供更准确的定位信号。SPPF[5]被简化为SimCSPSPF块，它带来了性能提高，速度下降可忽略不计。
2. 我们提出了一种锚辅助训练（AAT）策略，以在不影响推理效率的情况下，享受基于锚和无锚范例的优点。
3. 我们深化YOLOv6，使其在主干和颈部具有另一个阶段，这增强了它在COCO数据集上以高分辨率输入实现新的最先进性能。
4. 我们采用了一种新的自蒸馏策略来提高YOLOv6小模型的性能，其中DFL的较重分支在训练期间被用作增强的辅助回归分支，并在推断时被移除，以避免显著的速度下降。

## 2、YOLOv6-3.0方法
### 2.1、网络设计
在实践中，多尺度的特征集成已被证明是目标检测的关键和有效组成部分。特征金字塔网络（Feature Pyramid Network，FPN）被提出通过自上而下的路径来聚合高级语义特征和低级特征，从而提供更准确的定位。随后，为了增强分层特征表示的能力，已经在双向FPN上进行了一些工作。PANet在FPN上增加了一个额外的自底向上的路径，以缩短低层和顶层特征的信息路径，这有助于从低层特征传播准确的信号。BiFPN为不同的输入特征引入了可学习的权重，并简化了PAN，以实现更高的效率和更好的性能。提出了PRB-FPN，以通过具有双向融合和相关改进的并行FP结构来保留高质量特征以进行精确定位。

![](https://files.mdnice.com/user/33808/db4ccb63-c502-495f-a8e1-d552db6cbbdb.png)

在上述工作的激励下，我们设计了一个增强的PAN作为我们的检测颈。为了增加定位信号而不带来过多的计算负担，我们提出了一个双向级联（BiC）模块来集成三个相邻层的特征图，该模块将来自主干Ci−1的额外低级别特征融合到Pi中（图2）。在这种情况下，可以保留更精确的定位信号，这对于小物体的定位是重要的。

此外，我们将SPPF块简化为具有类似CSP的版本，称为SimCSPSPF块，这增强了表示能力。特别是，我们通过收缩隐藏层的通道和修饰空间金字塔池来修改YOLOv7中的SimSPPCPC块。此外，我们使用RepBlock（适用于小型号）或CSPStackRepBlock（用于大型号）升级CSPBlock，并相应地调整宽度和深度。YOLOv6的颈部表示为RepBi PAN，其框架如图2所示。


### 2.2、Anchor-Aided辅助训练
YOLOv6是一种无锚检测器，用于追求更高的推理速度。然而，我们实验发现，与无锚模式相比，基于锚的模式在相同设置下为YOLOv6-N带来了额外的性能增益，如表1所示。此外，在YOLOv6的早期版本中，采用基于锚的ATSS作为热身标签分配策略，这稳定了训练。

![](https://files.mdnice.com/user/33808/60f9e529-880d-423e-8c12-493de2006cdd.png)

鉴于此，我们提出了锚辅助训练（AAT），其中引入了基于锚的辅助分支，以结合基于锚和无锚范例的优点。它们同时应用于分类和回归头。图3显示了带有辅助设备的检测头。

在训练阶段，辅助分支和无锚分支从独立损失中学习，同时信号被完全传播。因此，来自辅助分支的附加嵌入引导信息被集成到主无锚头中。值得一提的是，在推断时去除了辅助分支，这在不降低速度的情况下提高了准确性性能。

### 2.3、Self-distillation
在YOLOv6的早期版本中，自我蒸馏仅在大型模型（即YOLOv6-M/L）中引入，该模型通过最小化教师和学生的课堂预测之间的KL差异来应用香草知识蒸馏技术。同时采用DFL作为回归损失，对类似于LD的盒回归进行自蒸馏。

知识蒸馏损失的表述为：

![](https://files.mdnice.com/user/33808/a622a1bb-6024-435e-8c16-4fedb99f1646.png)

其中，p cls t和p cls s分别为教师模型和学生模型的class预测，因此p reg t和p reg s为盒子回归预测。总体损失函数现在可以表述为：

![](https://files.mdnice.com/user/33808/1358b532-f340-4d18-ba35-051cdb0b4755.png)

其中Ldet是利用预测和标签计算的检测损失。引入超参数α来平衡两个损失。在培训的早期阶段，老师的软标签更容易学习。随着培训的继续，学生的表现将与老师相匹配，因此硬标签将对学生有更多帮助。在此基础上，我们将余弦权重衰减应用于α，以动态调整来自教师的硬标签和软标签的信息。α的公式为：

![](https://files.mdnice.com/user/33808/e4b80590-78a0-4146-bae3-e6007a1358ff.png)

其中Ei表示当前训练时期，Emax表示最大训练时期。

值得注意的是，DFL的引入需要回归分支的额外参数，这会显著影响小模型的推理速度。因此，我们专门为我们的小型模型设计了解耦本地化蒸馏（DLD），以提高性能而不降低速度。具体来说，我们附加了一个重辅助增强回归分支来合并DFL。在自我蒸馏过程中，学生配备了一个朴素回归分支和增强回归分支，而老师只使用辅助分支。请注意，仅使用硬标签来训练朴素回归分支，而根据来自教师和硬标签的信号来更新辅助分支。蒸馏后，保留自然回归分支，同时去除辅助分支。利用该策略，在不影响推理效率的情况下，可以显著保持DFL在蒸馏中的重回归分支的优势。

## 3、实验
### 3.1、消融实验

![](https://files.mdnice.com/user/33808/589edd13-8cf7-4f7b-8c00-d98c64ea0d14.png)

表3中的实验结果显示了本工作中所有贡献的有效性。经过BiC和SimCSPSPPF改造的网络的AP提高了0.6%。使用AAT和DLD时，准确率分别进一步提高了0.3%和0.7%。

#### 1、Network Design



![](https://files.mdnice.com/user/33808/372f192d-6070-4f37-9d3d-9be1893d8b32.png)

我们进行了一系列的实验来验证所提出的BiC模块的有效性。从表4中可以看出，仅在PAN的自上而下的路径上应用BiC模块，对YOLOv6-S/L分别有0.6%/0.4%的AP改进，而效率损失可以忽略不计。相比之下，当我们试图将BiC模块导入到自下而上的路径时，并没有获得积极的精度提高。可能的原因是自底向上路径上的BiC模块会导致检测头对不同尺度特征的混淆。因此，我们只是采用了自上而下的路径上的BiC模块。此外，研究结果表明，BiC模块显著提高了小目标检测的性能。对于YOLOv6-S和YOLOv6-L，对小物体的检测性能都提高了1.8%。

![](https://files.mdnice.com/user/33808/5bf271c7-1e08-4642-8b0b-7efd78027796.png)

此外，我们探讨了不同类型的SPP块的影响，包括SPPF和SPPCPC的简化变体（分别表示为SimSPPF和SimSPPCPC）以及我们的SimCSPSPF块。此外，我们在主干的前三个特征图（P3、P4和P5）上应用SimSPPF块，以验证其有效性，表示为SimSPPF*3。实验结果如表5所示。我们观察到，大量采用SimSPPF在计算复杂度增加的情况下，精度几乎没有提高。SimSPPCPC在YOLOv6-N/S上的性能分别优于SimSPPF 1.6%/0.3%AP，同时显著降低了推理速度。与SimSPPF相比，我们的SimCSSPPF版本可以分别为YOLOv6-N/S/M获得1.1%/0.4%/0.1%的性能增益。在推理效率方面，我们的SimCSPSPF块运行速度比SimSPPCPC快近10%，比SimSPPF稍慢。为了更好的精度效率权衡，在YOLOv6-N/S中引入了SimCSPSPF块。对于YOLOv6-M/L，采用SimSPPF块。

#### 2、Anchor-Aided训练

![](https://files.mdnice.com/user/33808/de9a2920-ede6-4949-a409-9d389cc8ae37.png)

在YOLOv6中验证了AAT的优点。如表6所示，它为YOLOv6-S/M/L分别带来了0.3%/0.5%/0.5% AP增益。值得注意的是，YOLOv6-N/S/M在小物体（APs）上的精度性能显著提高。对于YOLOv6-L，对大型对象（APl）的性能得到了进一步的提高。

#### 3、Self-distillation

![](https://files.mdnice.com/user/33808/2698ce35-a854-476e-97f1-fb6f9124e852.png)

我们在YOLOv6-L上验证了所提出的自蒸馏方法。为了进行公平的比较，我们还需要额外的整个训练周期来获得教师模型，从而通过使自蒸馏在基线之外加倍训练周期来验证模型的性能。如表7所示，与基线相比，没有权重衰减策略，性能没有得到改善。由于过拟合，使训练时期加倍甚至更糟糕。

在引入重量衰减后，该模型提高了0.6%的AP。

![](https://files.mdnice.com/user/33808/89cba798-c5fc-4b34-a262-44b459b57754.png)

此外，专门为小模型设计的DLD在YOLOv6-S上被消融。根据大型模型的自蒸馏，我们还将结果与用双时代训练的模型进行了比较。如表8所示，使用DLD的YOLOv6-S提供0.7%的AP提升，比加倍的训练好0.5%。

### 3.2、全系列YOLO对比结果

![](https://files.mdnice.com/user/33808/9dc9d9c6-345b-4914-ac07-2cc78c3851cc.png)

## 参考
[1].YOLOv6 v3.0: A Full-Scale Reloading.<br>