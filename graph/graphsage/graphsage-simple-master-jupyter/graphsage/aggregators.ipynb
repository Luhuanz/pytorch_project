{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import random\n",
    "\n",
    "\"\"\"\n",
    "Set of modules for aggregating embeddings of neighbors.\n",
    "\"\"\"\n",
    "\n",
    "# 实现聚合类，对邻居信息进行AGGREGATE\n",
    "class MeanAggregator(nn.Module):\n",
    "    \"\"\"\n",
    "    Aggregates a node's embeddings using mean of neighbors' embeddings\n",
    "    \"\"\"\n",
    "    def __init__(self, features, cuda=False, gcn=False): \n",
    "        \"\"\"\n",
    "        Initializes the aggregator for a specific graph.\n",
    "\n",
    "        features -- function mapping LongTensor of node ids to FloatTensor of feature values.\n",
    "        cuda -- whether to use GPU\n",
    "        gcn --- whether to perform concatenation GraphSAGE-style, or add self-loops GCN-style\n",
    "        \"\"\"\n",
    "\n",
    "        super(MeanAggregator, self).__init__()\n",
    "\n",
    "        self.features = features\n",
    "        self.cuda = cuda\n",
    "        self.gcn = gcn\n",
    "\n",
    "\n",
    "    def forward(self, nodes, to_neighs, num_sample=10):\n",
    "        \"\"\"\n",
    "        # batch中的点的列表\n",
    "        nodes --- list of nodes in a batch\n",
    "        # batch中每个点对应的邻居集合\n",
    "        to_neighs --- list of sets, each set is the set of neighbors for node in batch\n",
    "        num_sample --- number of neighbors to sample. No sampling if None.\n",
    "        \"\"\"\n",
    "        # Local pointers to functions (speed hack)\n",
    "        _set = set\n",
    "        if not num_sample is None:\n",
    "            _sample = random.sample\n",
    "            # 首先对每一个节点的邻居集合neigh进行遍历，判断一下已有邻居数和采样数大小，多于采样数进行抽样\n",
    "            # 对一个batch中的每一个节点的邻接点set进行sample\n",
    "            samp_neighs = [_set(_sample(to_neigh, \n",
    "                            num_sample,\n",
    "                            )) if len(to_neigh) >= num_sample else to_neigh for to_neigh in to_neighs]\n",
    "        else:\n",
    "            samp_neighs = to_neighs\n",
    "\n",
    "        # 将自己也作为自己的邻居点 (类似于GCN里面的A + I的操作)\n",
    "        if self.gcn:\n",
    "            samp_neighs = [samp_neigh + set([nodes[i]]) for i, samp_neigh in enumerate(samp_neighs)]\n",
    "        # *拆解列表后，转为为多个独立的元素作为参数给union，union函数进行去重合并\n",
    "        unique_nodes_list = list(set.union(*samp_neighs))\n",
    "        # 节点标号不一定都是从0开始的，创建一个字典，key为节点ID，value为节点序号 (old id到new id的转换，为下面列切片做准备)\n",
    "        unique_nodes = {n:i for i,n in enumerate(unique_nodes_list)}\n",
    "        # print(len(nodes), len(unique_nodes), len(samp_neighs))\n",
    "\n",
    "        # 构建缩小的邻接矩阵，即这个batch所用到的点所构成的小的邻接矩阵\n",
    "        # nodes表示batch内的节点，unique_nodes表示batch内的节点用到的所有邻居节点，unique_nodes > nodes\n",
    "        # len(samp_neighs)是这个batch的大小，即nodes数量，创建一个nodes * unique_nodes大小的邻接矩阵\n",
    "        mask = Variable(torch.zeros(len(samp_neighs), len(unique_nodes)))\n",
    "        # 列切片, 遍历每一个邻居集合的每一个元素，并且通过unique_nodes(old id)获取到节点对应的序号\n",
    "        column_indices = [unique_nodes[n] for samp_neigh in samp_neighs for n in samp_neigh]\n",
    "        # 行切片, 比如samp_neighs = [{3,5,9}, {2,8}, {2}]，行切片为[0,0,0,1,1,2]\n",
    "        row_indices = [i for i in range(len(samp_neighs)) for j in range(len(samp_neighs[i]))]\n",
    "        # 利用切片创建图的邻接矩阵\n",
    "        # 即(row_indices[i], column_indices[i])对应的位置为1\n",
    "        mask[row_indices, column_indices] = 1\n",
    "        if self.cuda:\n",
    "            mask = mask.cuda()\n",
    "\n",
    "        # 构造邻接矩阵\n",
    "        # 统计每一个节点的邻居数量\n",
    "        num_neigh = mask.sum(1, keepdim=True)\n",
    "        # 归一化(除以邻居数量)\n",
    "        mask = mask.div(num_neigh)\n",
    "        # embed_matrix: [n, m]\n",
    "        # n: unique_nodes\n",
    "        # m: dim\n",
    "        if self.cuda:\n",
    "            embed_matrix = self.features(torch.LongTensor(unique_nodes_list).cuda())\n",
    "        else:\n",
    "            embed_matrix = self.features(torch.LongTensor(unique_nodes_list))\n",
    "        # mask是nodes * unique_nodes大小的邻接矩阵, embed_matrix是unique_nodes * hid_size的特征矩阵\n",
    "        # 即A * X, 这里A是邻接矩阵， X是特征矩阵，这里一系列的操作是按batch训练需要采样出一个局部的A\n",
    "        to_feats = mask.mm(embed_matrix)\n",
    "        return to_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
