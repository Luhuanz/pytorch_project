{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encodes a node's using 'convolutional' GraphSage approach\n",
    "    \"\"\"\n",
    "    def __init__(self, features, feature_dim, \n",
    "            embed_dim, adj_lists, aggregator,\n",
    "            num_sample=10,\n",
    "            base_model=None, gcn=False, cuda=False, \n",
    "            feature_transform=False): \n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.features = features\n",
    "        # 变换前的hidden_size/维度\n",
    "        self.feat_dim = feature_dim\n",
    "        self.adj_lists = adj_lists\n",
    "        # 即邻居聚合后的mebedding: agg1 = MeanAggregator(features, cuda=True)\n",
    "        self.aggregator = aggregator\n",
    "        self.num_sample = num_sample\n",
    "        if base_model != None:\n",
    "            self.base_model = base_model\n",
    "\n",
    "        # 默认False, model.py里面设置成True\n",
    "        self.gcn = gcn\n",
    "        # 变换后的hidden_size/维度\n",
    "        self.embed_dim = embed_dim\n",
    "        self.cuda = cuda\n",
    "        self.aggregator.cuda = cuda\n",
    "        # 矩阵W维度 = 变换后维度 * 变换前维度\n",
    "        # 其中gcn表示是否拼接，如果拼接的话由于是\"自身向量||邻居聚合向量\", 所以维度为2倍\n",
    "        self.weight = nn.Parameter(\n",
    "                torch.FloatTensor(embed_dim, self.feat_dim if self.gcn else 2 * self.feat_dim))\n",
    "        init.xavier_uniform(self.weight)\n",
    "\n",
    "    def forward(self, nodes):\n",
    "        \"\"\"\n",
    "        Generates embeddings for a batch of nodes.\n",
    "\n",
    "        nodes     -- list of nodes\n",
    "        \"\"\"\n",
    "        # 调用aggregator.py文件中的MeanAggregator class的forward函数，得到聚合邻居的信息\n",
    "        neigh_feats = self.aggregator.forward(nodes, [self.adj_lists[int(node)] for node in nodes], \n",
    "                self.num_sample)\n",
    "        if not self.gcn:\n",
    "            if self.cuda:\n",
    "                self_feats = self.features(torch.LongTensor(nodes).cuda())\n",
    "            else:\n",
    "                self_feats = self.features(torch.LongTensor(nodes))\n",
    "            # 将自身和聚合邻居的向量拼接, algorithm 1 line 5的拼接部分\n",
    "            combined = torch.cat([self_feats, neigh_feats], dim=1)\n",
    "        else:\n",
    "            # 只用聚合邻居的向量来表示，不用自身信息, algorithm 1 line 5的拼接部分\n",
    "            combined = neigh_feats\n",
    "        # 送入到神经网络，algorithm 1 line 5乘以矩阵W\n",
    "        combined = F.relu(self.weight.mm(combined.t()))\n",
    "        # 经过一层GNN layer后的点的embedding，维度为embed_dim * nodes\n",
    "        return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
