{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0b0a533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dadecf7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from dgl.data import GINDataset\n",
    "from dataloader import GINDataLoader\n",
    "from parser import Parser\n",
    "from gin import GIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae47d540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, net, trainloader, optimizer, criterion, epoch):\n",
    "    net.train()\n",
    "\n",
    "    running_loss = 0\n",
    "    total_iters = len(trainloader)\n",
    "    # setup the offset to avoid the overlap with mouse cursor\n",
    "    bar = tqdm(range(total_iters), unit='batch', position=2, file=sys.stdout)\n",
    "\n",
    "    for pos, (graphs, labels) in zip(bar, trainloader):\n",
    "        # batch graphs will be shipped to device in forward part of model\n",
    "        labels = labels.to(args.device)\n",
    "        graphs = graphs.to(args.device)\n",
    "        feat = graphs.ndata.pop('attr')\n",
    "        outputs = net(graphs, feat)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # report\n",
    "        bar.set_description('epoch-{}'.format(epoch))\n",
    "    bar.close()\n",
    "    # the final batch will be aligned\n",
    "    running_loss = running_loss / total_iters\n",
    "\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43c9101e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_net(args, net, dataloader, criterion):\n",
    "    net.eval()\n",
    "\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for data in dataloader:\n",
    "        graphs, labels = data\n",
    "        graphs = graphs.to(args.device)\n",
    "        labels = labels.to(args.device)\n",
    "        feat = graphs.ndata.pop('attr')\n",
    "        total += len(labels)\n",
    "        outputs = net(graphs, feat)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total_correct += (predicted == labels.data).sum().item()\n",
    "        loss = criterion(outputs, labels)\n",
    "        # crossentropy(reduce=True) for default\n",
    "        total_loss += loss.item() * len(labels)\n",
    "\n",
    "    loss, acc = 1.0*total_loss / total, 1.0*total_correct / total\n",
    "\n",
    "    net.train()\n",
    "\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9afa3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "\n",
    "    # set up seeds, args.seed supported\n",
    "    torch.manual_seed(seed=args.seed)\n",
    "    np.random.seed(seed=args.seed)\n",
    "\n",
    "    is_cuda = not args.disable_cuda and torch.cuda.is_available()\n",
    "\n",
    "    if is_cuda:\n",
    "        args.device = torch.device(\"cuda:\" + str(args.device))\n",
    "        torch.cuda.manual_seed_all(seed=args.seed)\n",
    "    else:\n",
    "        args.device = torch.device(\"cpu\")\n",
    "\n",
    "    dataset = GINDataset(args.dataset, not args.learn_eps)\n",
    "\n",
    "    trainloader, validloader = GINDataLoader(\n",
    "        dataset, batch_size=args.batch_size, device=args.device,\n",
    "        seed=args.seed, shuffle=True,\n",
    "        split_name='fold10', fold_idx=args.fold_idx).train_valid_loader()\n",
    "    # or split_name='rand', split_ratio=0.7\n",
    "\n",
    "    model = GIN(\n",
    "        args.num_layers, args.num_mlp_layers,\n",
    "        dataset.dim_nfeats, args.hidden_dim, dataset.gclasses,\n",
    "        args.final_dropout, args.learn_eps,\n",
    "        args.graph_pooling_type, args.neighbor_pooling_type).to(args.device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()  # defaul reduce is true\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "\n",
    "    # it's not cost-effective to hanle the cursor and init 0\n",
    "    # https://stackoverflow.com/a/23121189\n",
    "    tbar = tqdm(range(args.epochs), unit=\"epoch\", position=3, ncols=0, file=sys.stdout)\n",
    "    vbar = tqdm(range(args.epochs), unit=\"epoch\", position=4, ncols=0, file=sys.stdout)\n",
    "    lrbar = tqdm(range(args.epochs), unit=\"epoch\", position=5, ncols=0, file=sys.stdout)\n",
    "\n",
    "    for epoch, _, _ in zip(tbar, vbar, lrbar):\n",
    "\n",
    "        train(args, model, trainloader, optimizer, criterion, epoch)\n",
    "        scheduler.step()\n",
    "\n",
    "        train_loss, train_acc = eval_net(\n",
    "            args, model, trainloader, criterion)\n",
    "        tbar.set_description(\n",
    "            'train set - average loss: {:.4f}, accuracy: {:.0f}%'\n",
    "            .format(train_loss, 100. * train_acc))\n",
    "\n",
    "        valid_loss, valid_acc = eval_net(\n",
    "            args, model, validloader, criterion)\n",
    "        vbar.set_description(\n",
    "            'valid set - average loss: {:.4f}, accuracy: {:.0f}%'\n",
    "            .format(valid_loss, 100. * valid_acc))\n",
    "\n",
    "        if not args.filename == \"\":\n",
    "            with open(args.filename, 'a') as f:\n",
    "                f.write('%s %s %s %s' % (\n",
    "                    args.dataset,\n",
    "                    args.learn_eps,\n",
    "                    args.neighbor_pooling_type,\n",
    "                    args.graph_pooling_type\n",
    "                ))\n",
    "                f.write(\"\\n\")\n",
    "                f.write(\"%f %f %f %f\" % (\n",
    "                    train_loss,\n",
    "                    train_acc,\n",
    "                    valid_loss,\n",
    "                    valid_acc\n",
    "                ))\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "        lrbar.set_description(\n",
    "            \"Learning eps with learn_eps={}: {}\".format(\n",
    "                args.learn_eps, [layer.eps.data.item() for layer in model.ginlayers]))\n",
    "\n",
    "    tbar.close()\n",
    "    vbar.close()\n",
    "    lrbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bfaa375",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h]\n",
      "                             [--dataset {MUTAG,COLLAB,IMDBBINARY,IMDBMULTI}]\n",
      "                             [--batch_size BATCH_SIZE] [--fold_idx FOLD_IDX]\n",
      "                             [--filename FILENAME] [--disable-cuda]\n",
      "                             [--device DEVICE] [--num_layers NUM_LAYERS]\n",
      "                             [--num_mlp_layers NUM_MLP_LAYERS]\n",
      "                             [--hidden_dim HIDDEN_DIM]\n",
      "                             [--graph_pooling_type {sum,mean,max}]\n",
      "                             [--neighbor_pooling_type {sum,mean,max}]\n",
      "                             [--learn_eps] [--seed SEED] [--epochs EPOCHS]\n",
      "                             [--lr LR] [--final_dropout FINAL_DROPOUT]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/zhengdong/Library/Jupyter/runtime/kernel-719b4665-20bd-45a7-8ef4-44b895aa7ba4.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "args = Parser(description='GIN').args\n",
    "print('show all arguments configuration...')\n",
    "print(args)\n",
    "\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520a06f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b585ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39046a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eced9314",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
