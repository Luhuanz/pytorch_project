{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0b0a533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dadecf7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from dgl.data import GINDataset\n",
    "from dataloader import GINDataLoader\n",
    "from parser import Parser\n",
    "from gin import GIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae47d540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, net, trainloader, optimizer, criterion, epoch):\n",
    "    net.train()\n",
    "\n",
    "    running_loss = 0\n",
    "    total_iters = len(trainloader)\n",
    "    # setup the offset to avoid the overlap with mouse cursor\n",
    "    bar = tqdm(range(total_iters), unit='batch', position=2, file=sys.stdout)\n",
    "\n",
    "    for pos, (graphs, labels) in zip(bar, trainloader):\n",
    "        # batch graphs will be shipped to device in forward part of model\n",
    "        labels = labels.to(args.device)\n",
    "        graphs = graphs.to(args.device)\n",
    "        feat = graphs.ndata.pop('attr')\n",
    "        outputs = net(graphs, feat)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # report\n",
    "        bar.set_description('epoch-{}'.format(epoch))\n",
    "    bar.close()\n",
    "    # the final batch will be aligned\n",
    "    running_loss = running_loss / total_iters\n",
    "\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43c9101e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_net(args, net, dataloader, criterion):\n",
    "    net.eval()\n",
    "\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for data in dataloader:\n",
    "        graphs, labels = data\n",
    "        graphs = graphs.to(args.device)\n",
    "        labels = labels.to(args.device)\n",
    "        feat = graphs.ndata.pop('attr')\n",
    "        total += len(labels)\n",
    "        outputs = net(graphs, feat)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        total_correct += (predicted == labels.data).sum().item()\n",
    "        loss = criterion(outputs, labels)\n",
    "        # crossentropy(reduce=True) for default\n",
    "        total_loss += loss.item() * len(labels)\n",
    "\n",
    "    loss, acc = 1.0*total_loss / total, 1.0*total_correct / total\n",
    "\n",
    "    net.train()\n",
    "\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9afa3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "\n",
    "    # set up seeds, args.seed supported\n",
    "    torch.manual_seed(seed=args.seed)\n",
    "    np.random.seed(seed=args.seed)\n",
    "\n",
    "    is_cuda = not args.disable_cuda and torch.cuda.is_available()\n",
    "\n",
    "    if is_cuda:\n",
    "        args.device = torch.device(\"cuda:\" + str(args.device))\n",
    "        torch.cuda.manual_seed_all(seed=args.seed)\n",
    "    else:\n",
    "        args.device = torch.device(\"cpu\")\n",
    "\n",
    "    dataset = GINDataset(args.dataset, not args.learn_eps)\n",
    "\n",
    "    trainloader, validloader = GINDataLoader(\n",
    "        dataset, batch_size=args.batch_size, device=args.device,\n",
    "        seed=args.seed, shuffle=True,\n",
    "        split_name='fold10', fold_idx=args.fold_idx).train_valid_loader()\n",
    "    # or split_name='rand', split_ratio=0.7\n",
    "\n",
    "    model = GIN(\n",
    "        args.num_layers, args.num_mlp_layers,\n",
    "        dataset.dim_nfeats, args.hidden_dim, dataset.gclasses,\n",
    "        args.final_dropout, args.learn_eps,\n",
    "        args.graph_pooling_type, args.neighbor_pooling_type).to(args.device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()  # defaul reduce is true\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "\n",
    "    # it's not cost-effective to hanle the cursor and init 0\n",
    "    # https://stackoverflow.com/a/23121189\n",
    "    tbar = tqdm(range(args.epochs), unit=\"epoch\", position=3, ncols=0, file=sys.stdout)\n",
    "    vbar = tqdm(range(args.epochs), unit=\"epoch\", position=4, ncols=0, file=sys.stdout)\n",
    "    lrbar = tqdm(range(args.epochs), unit=\"epoch\", position=5, ncols=0, file=sys.stdout)\n",
    "\n",
    "    for epoch, _, _ in zip(tbar, vbar, lrbar):\n",
    "\n",
    "        train(args, model, trainloader, optimizer, criterion, epoch)\n",
    "        scheduler.step()\n",
    "\n",
    "        train_loss, train_acc = eval_net(\n",
    "            args, model, trainloader, criterion)\n",
    "        tbar.set_description(\n",
    "            'train set - average loss: {:.4f}, accuracy: {:.0f}%'\n",
    "            .format(train_loss, 100. * train_acc))\n",
    "\n",
    "        valid_loss, valid_acc = eval_net(\n",
    "            args, model, validloader, criterion)\n",
    "        vbar.set_description(\n",
    "            'valid set - average loss: {:.4f}, accuracy: {:.0f}%'\n",
    "            .format(valid_loss, 100. * valid_acc))\n",
    "\n",
    "        if not args.filename == \"\":\n",
    "            with open(args.filename, 'a') as f:\n",
    "                f.write('%s %s %s %s' % (\n",
    "                    args.dataset,\n",
    "                    args.learn_eps,\n",
    "                    args.neighbor_pooling_type,\n",
    "                    args.graph_pooling_type\n",
    "                ))\n",
    "                f.write(\"\\n\")\n",
    "                f.write(\"%f %f %f %f\" % (\n",
    "                    train_loss,\n",
    "                    train_acc,\n",
    "                    valid_loss,\n",
    "                    valid_acc\n",
    "                ))\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "        lrbar.set_description(\n",
    "            \"Learning eps with learn_eps={}: {}\".format(\n",
    "                args.learn_eps, [layer.eps.data.item() for layer in model.ginlayers]))\n",
    "\n",
    "    tbar.close()\n",
    "    vbar.close()\n",
    "    lrbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bfaa375",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show all arguments configuration...\n",
      "Namespace(batch_size=32, dataset='MUTAG', device=0, disable_cuda=False, epochs=10, filename='', final_dropout=0.5, fold_idx=0, graph_pooling_type='sum', hidden_dim=64, learn_eps=False, lr=0.01, neighbor_pooling_type='sum', num_layers=5, num_mlp_layers=2, seed=0)\n",
      "train_set : test_set = %d : %d 169 19\n",
      "\n",
      "\n",
      "\n",
      "  0% 0/10 [00:00<?, ?epoch/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0% 0/10 [00:00<?, ?epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0% 0/10 [00:00<?, ?epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-0:   0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-0:   0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-0:  33%|███▎      | 2/6 [00:00<00:00, 12.79batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-0:  33%|███▎      | 2/6 [00:00<00:00, 12.79batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-0:  33%|███▎      | 2/6 [00:00<00:00, 12.79batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-0:  67%|██████▋   | 4/6 [00:00<00:00, 12.84batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-0:  67%|██████▋   | 4/6 [00:00<00:00, 12.84batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-0: 100%|██████████| 6/6 [00:00<00:00, 14.71batch/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "train set - average loss: 2.2233, accuracy: 66%:   0% 0/10 [00:00<?, ?epoch/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "valid set - average loss: 2.1559, accuracy: 68%:   0% 0/10 [00:00<?, ?epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learning eps with learn_eps=False: [0.0, 0.0, 0.0, 0.0]:   0% 0/10 [00:00<?, ?epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "train set - average loss: 2.2233, accuracy: 66%:  10% 1/10 [00:00<00:04,  1.91epoch/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "valid set - average loss: 2.1559, accuracy: 68%:  10% 1/10 [00:00<00:04,  1.92epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learning eps with learn_eps=False: [0.0, 0.0, 0.0, 0.0]:  10% 1/10 [00:00<00:04,  1.96epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-1:   0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-1:   0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-1:   0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-1:   0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-1:  67%|██████▋   | 4/6 [00:00<00:00, 30.98batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-1:  67%|██████▋   | 4/6 [00:00<00:00, 30.98batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-1: 100%|██████████| 6/6 [00:00<00:00, 32.03batch/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "train set - average loss: 4.9169, accuracy: 67%:  10% 1/10 [00:00<00:04,  1.91epoch/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "valid set - average loss: 4.5945, accuracy: 68%:  10% 1/10 [00:00<00:04,  1.92epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learning eps with learn_eps=False: [0.0, 0.0, 0.0, 0.0]:  10% 1/10 [00:00<00:04,  1.96epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "train set - average loss: 4.9169, accuracy: 67%:  20% 2/10 [00:00<00:03,  2.53epoch/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "valid set - average loss: 4.5945, accuracy: 68%:  20% 2/10 [00:00<00:03,  2.52epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learning eps with learn_eps=False: [0.0, 0.0, 0.0, 0.0]:  20% 2/10 [00:00<00:03,  2.52epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-2:   0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-2:   0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-2:   0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-2:  50%|█████     | 3/6 [00:00<00:00, 23.90batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-2:  50%|█████     | 3/6 [00:00<00:00, 23.90batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-2:  50%|█████     | 3/6 [00:00<00:00, 23.90batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-2: 100%|██████████| 6/6 [00:00<00:00, 27.88batch/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "train set - average loss: 12.4740, accuracy: 66%:  20% 2/10 [00:01<00:03,  2.53epoch/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "valid set - average loss: 14.2958, accuracy: 68%:  20% 2/10 [00:01<00:03,  2.52epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learning eps with learn_eps=False: [0.0, 0.0, 0.0, 0.0]:  20% 2/10 [00:01<00:03,  2.52epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "train set - average loss: 12.4740, accuracy: 66%:  30% 3/10 [00:01<00:02,  2.64epoch/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "valid set - average loss: 14.2958, accuracy: 68%:  30% 3/10 [00:01<00:02,  2.65epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learning eps with learn_eps=False: [0.0, 0.0, 0.0, 0.0]:  30% 3/10 [00:01<00:02,  2.67epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-3:   0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-3:   0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-3:   0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-3:  50%|█████     | 3/6 [00:00<00:00, 25.79batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-3:  50%|█████     | 3/6 [00:00<00:00, 25.79batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-3:  50%|█████     | 3/6 [00:00<00:00, 25.79batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-3: 100%|██████████| 6/6 [00:00<00:00, 29.08batch/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "train set - average loss: 24.1617, accuracy: 66%:  30% 3/10 [00:01<00:02,  2.64epoch/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "valid set - average loss: 25.1341, accuracy: 68%:  30% 3/10 [00:01<00:02,  2.65epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learning eps with learn_eps=False: [0.0, 0.0, 0.0, 0.0]:  30% 3/10 [00:01<00:02,  2.67epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "train set - average loss: 24.1617, accuracy: 66%:  40% 4/10 [00:01<00:02,  2.86epoch/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "valid set - average loss: 25.1341, accuracy: 68%:  40% 4/10 [00:01<00:02,  2.86epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learning eps with learn_eps=False: [0.0, 0.0, 0.0, 0.0]:  40% 4/10 [00:01<00:02,  2.87epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-4:   0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-4:   0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-4:   0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-4:  50%|█████     | 3/6 [00:00<00:00, 27.37batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-4:  50%|█████     | 3/6 [00:00<00:00, 27.37batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-4:  50%|█████     | 3/6 [00:00<00:00, 27.37batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-4: 100%|██████████| 6/6 [00:00<00:00, 30.22batch/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "train set - average loss: 11.9958, accuracy: 69%:  40% 4/10 [00:01<00:02,  2.86epoch/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "valid set - average loss: 11.6217, accuracy: 68%:  40% 4/10 [00:01<00:02,  2.86epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learning eps with learn_eps=False: [0.0, 0.0, 0.0, 0.0]:  40% 4/10 [00:01<00:02,  2.87epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "train set - average loss: 11.9958, accuracy: 69%:  50% 5/10 [00:01<00:01,  3.07epoch/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "valid set - average loss: 11.6217, accuracy: 68%:  50% 5/10 [00:01<00:01,  3.08epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learning eps with learn_eps=False: [0.0, 0.0, 0.0, 0.0]:  50% 5/10 [00:01<00:01,  3.09epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-5:   0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-5:   0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-5:   0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-5:   0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-5:  67%|██████▋   | 4/6 [00:00<00:00, 33.64batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-5:  67%|██████▋   | 4/6 [00:00<00:00, 33.64batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-5: 100%|██████████| 6/6 [00:00<00:00, 29.76batch/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "train set - average loss: 5.3867, accuracy: 72%:  50% 5/10 [00:02<00:01,  3.07epoch/s] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "valid set - average loss: 6.8876, accuracy: 74%:  50% 5/10 [00:02<00:01,  3.08epoch/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learning eps with learn_eps=False: [0.0, 0.0, 0.0, 0.0]:  50% 5/10 [00:02<00:01,  3.09epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "train set - average loss: 5.3867, accuracy: 72%:  60% 6/10 [00:02<00:01,  3.15epoch/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "valid set - average loss: 6.8876, accuracy: 74%:  60% 6/10 [00:02<00:01,  3.16epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learning eps with learn_eps=False: [0.0, 0.0, 0.0, 0.0]:  60% 6/10 [00:02<00:01,  3.16epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-6:   0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-6:  17%|█▋        | 1/6 [00:00<00:01,  4.57batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-6:  17%|█▋        | 1/6 [00:00<00:01,  4.57batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-6:  17%|█▋        | 1/6 [00:00<00:01,  4.57batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-6:  50%|█████     | 3/6 [00:00<00:00, 10.07batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-6:  50%|█████     | 3/6 [00:00<00:00, 10.07batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-6:  50%|█████     | 3/6 [00:00<00:00, 10.07batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-6:  83%|████████▎ | 5/6 [00:00<00:00, 13.18batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-6: 100%|██████████| 6/6 [00:00<00:00, 12.68batch/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "train set - average loss: 2.2951, accuracy: 79%:  60% 6/10 [00:02<00:01,  3.15epoch/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "valid set - average loss: 2.0275, accuracy: 79%:  60% 6/10 [00:02<00:01,  3.16epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learning eps with learn_eps=False: [0.0, 0.0, 0.0, 0.0]:  60% 6/10 [00:02<00:01,  3.16epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set - average loss: 2.2951, accuracy: 79%:  70% 7/10 [00:02<00:01,  2.49epoch/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "valid set - average loss: 2.0275, accuracy: 79%:  70% 7/10 [00:02<00:01,  2.49epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learning eps with learn_eps=False: [0.0, 0.0, 0.0, 0.0]:  70% 7/10 [00:02<00:01,  2.49epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-7:   0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-7:   0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-7:   0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-7:  50%|█████     | 3/6 [00:00<00:00, 27.58batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-7:  50%|█████     | 3/6 [00:00<00:00, 27.58batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-7:  50%|█████     | 3/6 [00:00<00:00, 27.58batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-7:  50%|█████     | 3/6 [00:00<00:00, 27.58batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-7: 100%|██████████| 6/6 [00:00<00:00, 19.75batch/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "train set - average loss: 2.1476, accuracy: 82%:  70% 7/10 [00:03<00:01,  2.49epoch/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "valid set - average loss: 2.1374, accuracy: 79%:  70% 7/10 [00:03<00:01,  2.49epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learning eps with learn_eps=False: [0.0, 0.0, 0.0, 0.0]:  70% 7/10 [00:03<00:01,  2.49epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "train set - average loss: 2.1476, accuracy: 82%:  80% 8/10 [00:03<00:00,  2.46epoch/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "valid set - average loss: 2.1374, accuracy: 79%:  80% 8/10 [00:03<00:00,  2.47epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learning eps with learn_eps=False: [0.0, 0.0, 0.0, 0.0]:  80% 8/10 [00:03<00:00,  2.47epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-8:   0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-8:   0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-8:  33%|███▎      | 2/6 [00:00<00:00, 16.17batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-8:  33%|███▎      | 2/6 [00:00<00:00, 16.17batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-8:  33%|███▎      | 2/6 [00:00<00:00, 16.17batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-8:  33%|███▎      | 2/6 [00:00<00:00, 16.17batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-8:  83%|████████▎ | 5/6 [00:00<00:00, 19.38batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-8: 100%|██████████| 6/6 [00:00<00:00, 19.74batch/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "train set - average loss: 0.9343, accuracy: 83%:  80% 8/10 [00:03<00:00,  2.46epoch/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "valid set - average loss: 0.7111, accuracy: 84%:  80% 8/10 [00:03<00:00,  2.47epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learning eps with learn_eps=False: [0.0, 0.0, 0.0, 0.0]:  80% 8/10 [00:03<00:00,  2.47epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "train set - average loss: 0.9343, accuracy: 83%:  90% 9/10 [00:03<00:00,  2.42epoch/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "valid set - average loss: 0.7111, accuracy: 84%:  90% 9/10 [00:03<00:00,  2.42epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learning eps with learn_eps=False: [0.0, 0.0, 0.0, 0.0]:  90% 9/10 [00:03<00:00,  2.41epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-9:   0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-9:   0%|          | 0/6 [00:00<?, ?batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-9:  33%|███▎      | 2/6 [00:00<00:00, 18.80batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-9:  33%|███▎      | 2/6 [00:00<00:00, 18.80batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-9:  33%|███▎      | 2/6 [00:00<00:00, 18.80batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-9:  67%|██████▋   | 4/6 [00:00<00:00, 17.43batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-9:  67%|██████▋   | 4/6 [00:00<00:00, 17.43batch/s]\u001b[A\u001b[A\n",
      "\n",
      "epoch-9: 100%|██████████| 6/6 [00:00<00:00, 19.40batch/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "train set - average loss: 1.8334, accuracy: 79%:  90% 9/10 [00:03<00:00,  2.42epoch/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "valid set - average loss: 4.3162, accuracy: 74%:  90% 9/10 [00:03<00:00,  2.42epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Learning eps with learn_eps=False: [0.0, 0.0, 0.0, 0.0]:  90% 9/10 [00:03<00:00,  2.41epoch/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "train set - average loss: 1.8334, accuracy: 79%: 100% 10/10 [00:03<00:00,  2.55epoch/s]\u001b[A\u001b[A\u001b[A\n",
      "Learning eps with learn_eps=False: [0.0, 0.0, 0.0, 0.0]:  90% 9/10 [00:03<00:00,  2.30epoch/s]\n",
      "valid set - average loss: 4.3162, accuracy: 74%:  90% 9/10 [00:03<00:00,  2.29epoch/s]\n"
     ]
    }
   ],
   "source": [
    "args = Parser(description='GIN').args\n",
    "print('show all arguments configuration...')\n",
    "print(args)\n",
    "\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520a06f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b585ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39046a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eced9314",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
